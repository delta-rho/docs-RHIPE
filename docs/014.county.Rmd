### Read and Divide by County ###
Our division method for the housing data will be to divide by county,
so there will be 2883 subsets. Each subset will be a `data.frame` object with 4
column variables: `date`, `units`, `listing`, and `selling`.
`FIPS`, `state`, and `county` are not column variables because each has only one
value for each county; their values are added to the `data.frame` as
attributes.

The first step is to read each line of the file `house.txt` into R. By
convention, `RHIPE` takes each line of a text file to be a key-value pair.
The line number is the key. The value is the data for the line, in our case
the 7 observations of the 7 variables of the data for one month and one county.

Each line is read as part of Map R code written by the user. The Map input
key-value pairs are the above line key-value pairs. Each line also has a Map
output key-value pair. The key identifies the county. `FIPS` could have been
enough to do this, but it is specified as a character vector with three
elements: the 3-vector values of `FIPS`, `state`, and `county`.
This is done so that later all three can be added to the subset `data.frame`.
The output value for each output key is the  observations of `date`, `units`,
`listing`, and `selling` from the line for that key.

The Map output key-value pairs are the input key-value pairs for the Reduce R
code written by the user. Reduce assembles these into groups by key,
that is, the county. Then the Reduce R code is applied to the output
values of  each group collectively to create the subset `data.frame` object
for each county. Each row is the value of one Reduce input key-value pair:
observations of `date`, `units`, `listing`, and `selling` for one housing unit.
`FIPS`, `state`, and `county` are added to the `data.frame` as attributes.
Finally, Reduce writes
each subset `data.frame` object to a directory in the HDFS specified by the
user.  The subsets are written as Reduce output key-value pairs.
The output keys are the the values of `FIPS`. The output values are the county
`data.frame` objects.

#### The RHIPE Manager: rhwatch() ####

We begin with the `RHIPE` R function `rhwatch()`. It
runs the R code you write to specify
Map and Reduce operations, takes your specification of input and
output files, and manages key-value pairs for you.

The code for the county division is
```{r eval=FALSE, tidy=FALSE}
mr1 <- rhwatch(
  map      = map1,
  reduce   = reduce1,
  input    = rhfmt("/yourloginname/housing/housing.txt", type = "text"),
  output   = rhfmt("/yourloginname/housing/byCounty", type = "sequence"),
  mapred   = list(
    mapred.reduce.tasks = 10
  ),
  readback = FALSE
)
```
Arguments `map` and `reduce` take your Map and Reduce R code, which will be
described below. `input` specifies the input to be the text file in the HDFS
that we put there earlier using `rhput()`. The file supplies input key-value
pairs for the Map code.  `output` specifies the file name
into which final output key-value pairs of the Reduce code that are written to
the HDFS. `rhwatch()` creates this file if it does not exist, or overwrites it
if it does not.

In our division by county here, the Reduce recombination outputs are the
2883 county `data.frame` R objects. They are a `list` object that describes the
key-value pairs: `FIPS` key and `data.frame` value. There is one `list` element
per pair; that element is itself a list with two elements, the `FIPS` key and
then the `data.frame` value.

The argument `mapred` in our case is given a list with one element that
specifies one Hadoop configuration parameter: the maximum number of map
tasks that can be run simultaneously, 10, and the maximum number of reduce
tasks that can run simultaneously, 10. This is done to keep Hadoop from asking
for more resources than can be supplied to avoid failures and warnings of
various kinds.  The number 10 was specified for a very small cluster with just
16 that served both the Hadoop and the R session. A full discussion
of Hadoop configuration parameters is beyond the scope of this documentation. 

The Reduce `list` output can also be written to the R global environment of
the R session. One use of this is analytic recombination in the R session
when the outputs are a small enough dataset. You can do this with the argument
`readback`.  If `TRUE`, the list is also written to the global environment.
If `FALSE`, it is not. If FALSE, it can be written latter using the RHIPE R
function `rhread()`.
```{r eval=FALSE, tidy=FALSE}
countySubsets <- rhread("/yourloginname/housing/byCounty")
```
Suppose you just want to look over the `byCounty` file on the HDFS just to see
if all is well, but that this can be done by looking at a small number of
key-value pairs, say 10. The code for this is

```{r eval=FALSE, tidy=FALSE}
countySubsets <- rhread("/yourloginname/housing/byCounty", max = 10)
```

```
Read 10 objects(31.39 KB) in 0.04 seconds
```
Then you can look at the list of length 10 in various was such as

```{r eval=FALSE, tidy=FALSE}
keys <- unlist(lapply(countySubsets, "[[", 1))
keys
```
```
 [1] "01013" "01031" "01059" "01077" "01095" "01103" "01121" "04001" "05019" "05037"
```

```{r eval=FALSE, tidy=FALSE}
attributes(countySubsets[[1]][[2]])
```
```
$names
[1] "date"             "units"            "listing"             "selling"

$row.names
 [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32
[33] 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 
[65] 65 66

$state
[1] "AL"

$FIPS
[1] "01013"

$county
[1] "Butler"

$class
[1] "data.frame"
```

#### Map R Code ####
The Map R code for the county division is

```{r eval =FALSE, tidy=FALSE}
map1 <- expression({
  lapply(seq_along(map.keys), function(r) {
    line = strsplit(map.values[[r]], ",")[[1]]
    outputkey <- line[1:3]
    outputvalue <- data.frame(
      date = as.numeric(line[4]),
      units =  as.numeric(line[5]),
      listing = as.numeric(line[6]),
      selling = as.numeric(line[7]),
      stringsAsFactors = FALSE
    )
  rhcollect(outputkey, outputvalue)
  })
})
```
Map has input key-value pairs, and output key-value pairs. Each pair has an
identifier, the key, and numeric-categorical information, the value. 
The Map R code is applied to each input key-value pair, producing one
output key-value pair. Each application of the Map code to a
key-value pair is carried out by a mapper, and there are many mappers running
in parallel without communication (embarrassingly parallel) until the Map job
completes.

`RHIPE` creates input key-value pair `list` objects, `map.keys` and
`map.values`, based on information that it has.
Let `r` be an integer from 1 to the number of input key-value pairs.
`map.values[[r]]` is the value for key `map.keys[[r]]`.
The housing data inputs come from a text file in the HDFS, housing.txt,
By RHIPE convention, for a text file, each Map input key is a text file line
number, and the corresponding  Map input value is the observations in the line,
read into R as a single text string.
In our case each line value is the observations of the 7 county variables for the line.

This Map code is really a `for loop` with `r` as the looping variable,
but is done by `lapply()` because it is
in general faster than `for r in 1:length(map.keys)`.
The loop proceeds through the input keys, specified by the first argument of
`lapply`.  The second argument of the above `lapply` defines the Map expression
with the argument `r`, an index for the Map keys and values.

The function `strsplit()` splits each character-string line input value
into the individual observations of the text line. The result, `line`,
is a `list` of length one whose element is a `character vector` whose elements
are the line observations. In our case, the
observations are a `character vector` of length 7, in order:
`FIPS`, `county`, `state`, `date`, `units`, `listing`, `selling`.

Next we turn to the Map output key-value pairs.
`outputkey` for each text line is a character vector of length 3 with `FIPS`,
`county`, and `state`. `outputvalue` is a `data.frame` with one row
and 4 columns, the observations of `date`, `units`, `listing`, and `selling`, 
each a `numeric` object.

The argument of `data.frame`, `stringsAsFactors`, is
is given the value `FALSE`. This leaves character vectors in the `data.frame`
as is, and does on convert to a `factor`.

The RHIPE function `rhcollect()` forms a Map output key-value pair for each
line, and writes the results to the HDFS as a key-value pair `list` object.

#### Reduce R Code ####
The Reduce R code for the county division is

```{r eval=FALSE, tidy=FALSE}
reduce1 <- expression(
  pre = {
    reduceoutputvalue <- data.frame()
  },
  reduce = {
    reduceoutputvalue <- rbind(reduceoutputvalue, do.call(rbind, reduce.values))
  },
  post = {
    reduceoutputkey <- reduce.key[1]
    attr(reduceoutputvalue, "location") <- reduce.key[1:3]
    names(attr(reduceoutputvalue, "location")) <- c("FIPS","county","state")
    rhcollect(reduceoutputkey, reduceoutputvalue)
  }
)
```

The output key-value pairs of Map are the input key-value pairs to Reduce.
The first task of Reduce is to group its input key-value pairs by unique key.
The Reduce R code is applied to the key-value pairs of each group by a
reducer. The number of groups varies in applications from just one, with a
single Reduce output, to many.
For multiple groups, the reducers run in parallel, without communication,
until the Reduce job completes.

`RHIPE` creates two list objects `reduce.key` and `reduce.values`.
Each element of `reduce.key` is the key for one group, and the corresponding
element of `reduce.values` has the values for the group to which the Reduce
code is applied..  Now in our case, the key is county and the values are the
observations of  `date`, `units`, `listing`, and `selling` for the all housing
units in the county.

Note the Reduce code has a certain structure: expressions `pre`, `reduce`,
and `post`. In our case `pre` initializes `reduceoutputvalue` to a
`data.frame()`. `reduce` assembles the county `data.frame` as the
reducer receives the values through `rbind(reduceoutputvalue, do.call(rbind,
reduce.values))`; this uses `rbind()` to add rows to the `data.frame` object.
`post` operates further on the result of `reduce`. In our case it first assigns
the observation of `FIPS` as the key. Then it adds `FIPS`,`county`, and
`state` as `attributes`. Finally the RHIPE function
`rhcollect()` forms a Reduce output key-value pair `list`, and writes it to the
HDFS.
